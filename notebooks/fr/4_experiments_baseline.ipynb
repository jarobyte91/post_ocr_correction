{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "sns.set(rc = {'figure.figsize':(10, 6)})\n",
    "pd.set_option(\"precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/home/jarobyte/scratch/guemes/icdar/fr/baseline/experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(folder)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7593d1e720c940ebbb7a49cecd9f4f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>dev_loss</th>\n",
       "      <th>dev_error_rate</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>model</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>...</th>\n",
       "      <th>feedforward_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>decoder_layers</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>parameters</th>\n",
       "      <th>encoder_tokens</th>\n",
       "      <th>decoder_tokens</th>\n",
       "      <th>experiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.722</td>\n",
       "      <td>74.446</td>\n",
       "      <td>2.723</td>\n",
       "      <td>79.146</td>\n",
       "      <td>8.101</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477826</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>22722342_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.604</td>\n",
       "      <td>73.192</td>\n",
       "      <td>2.683</td>\n",
       "      <td>79.935</td>\n",
       "      <td>16.224</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477826</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>22722342_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.563</td>\n",
       "      <td>72.201</td>\n",
       "      <td>2.621</td>\n",
       "      <td>77.968</td>\n",
       "      <td>24.370</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477826</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>22722342_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.487</td>\n",
       "      <td>70.203</td>\n",
       "      <td>2.579</td>\n",
       "      <td>76.465</td>\n",
       "      <td>32.504</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477826</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>22722342_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.450</td>\n",
       "      <td>69.196</td>\n",
       "      <td>2.567</td>\n",
       "      <td>76.039</td>\n",
       "      <td>40.636</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477826</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>22722342_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_error_rate  dev_loss  dev_error_rate  \\\n",
       "0      1       2.722            74.446     2.723          79.146   \n",
       "1      2       2.604            73.192     2.683          79.935   \n",
       "2      3       2.563            72.201     2.621          77.968   \n",
       "3      4       2.487            70.203     2.579          76.465   \n",
       "4      5       2.450            69.196     2.567          76.039   \n",
       "\n",
       "   training_minutes  learning_rate  weight_decay        model  \\\n",
       "0             8.101      1.000e-04          0.01  Transformer   \n",
       "1            16.224      1.000e-04          0.01  Transformer   \n",
       "2            24.370      1.000e-04          0.01  Transformer   \n",
       "3            32.504      1.000e-04          0.01  Transformer   \n",
       "4            40.636      1.000e-04          0.01  Transformer   \n",
       "\n",
       "   max_sequence_length  ...  feedforward_dimension  encoder_layers  \\\n",
       "0                  110  ...                    512               3   \n",
       "1                  110  ...                    512               3   \n",
       "2                  110  ...                    512               3   \n",
       "3                  110  ...                    512               3   \n",
       "4                  110  ...                    512               3   \n",
       "\n",
       "   decoder_layers  attention_heads  activation dropout  parameters  \\\n",
       "0               3                8        relu     0.0     1477826   \n",
       "1               3                8        relu     0.0     1477826   \n",
       "2               3                8        relu     0.0     1477826   \n",
       "3               3                8        relu     0.0     1477826   \n",
       "4               3                8        relu     0.0     1477826   \n",
       "\n",
       "   encoder_tokens  decoder_tokens  experiment_id  \n",
       "0             194             194    22722342_10  \n",
       "1             194             194    22722342_10  \n",
       "2             194             194    22722342_10  \n",
       "3             194             194    22722342_10  \n",
       "4             194             194    22722342_10  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = pd.concat([pd.read_csv(folder + f) \n",
    "                       for f in tqdm(os.listdir(folder))])\\\n",
    ".assign(dropout = lambda df: df.dropout.round(2))\n",
    "print(logs.shape)\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>dev_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22694232_1</th>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-02</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.867</td>\n",
       "      <td>2.423</td>\n",
       "      <td>2.548</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_10</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>71.005</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.461</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_11</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>71.389</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.645</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_12</th>\n",
       "      <td>1.478</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>101.180</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.262</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_2</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000e-02</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>72.071</td>\n",
       "      <td>2.436</td>\n",
       "      <td>2.547</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_3</th>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_4</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000e-02</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>70.698</td>\n",
       "      <td>2.371</td>\n",
       "      <td>2.467</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_5</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>75.956</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.883</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_6</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>70.627</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.515</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694232_7</th>\n",
       "      <td>1.015</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-02</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>72.318</td>\n",
       "      <td>2.452</td>\n",
       "      <td>2.575</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               parameters  dropout  weight_decay  embedding_dimension  \\\n",
       "experiment_id                                                           \n",
       "22694232_1          1.478      0.1     1.000e-02                  128   \n",
       "22694232_10         1.015      0.1     1.000e-03                  128   \n",
       "22694232_11         1.015      0.4     1.000e-03                  128   \n",
       "22694232_12         1.478      0.2     1.000e-04                  128   \n",
       "22694232_2          1.015      0.2     1.000e-02                  128   \n",
       "22694232_3          1.478      0.5     1.000e-04                  128   \n",
       "22694232_4          1.015      0.2     1.000e-02                  128   \n",
       "22694232_5          1.015      0.5     1.000e-03                  128   \n",
       "22694232_6          1.015      0.2     1.000e-03                  128   \n",
       "22694232_7          1.015      0.5     1.000e-02                  128   \n",
       "\n",
       "               encoder_layers  training_minutes  train_loss  dev_loss  epoch  \n",
       "experiment_id                                                                 \n",
       "22694232_1                  3           112.867       2.423     2.548     12  \n",
       "22694232_10                 2            71.005       0.413     0.461     12  \n",
       "22694232_11                 2            71.389       0.600     0.645     12  \n",
       "22694232_12                 3           101.180       0.183     0.262     12  \n",
       "22694232_2                  2            72.071       2.436     2.547     10  \n",
       "22694232_3                  3           112.512       0.288     0.318     10  \n",
       "22694232_4                  2            70.698       2.371     2.467     11  \n",
       "22694232_5                  2            75.956       1.037     0.883     12  \n",
       "22694232_6                  2            70.627       0.467     0.515     12  \n",
       "22694232_7                  2            72.318       2.452     2.575     11  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = logs\\\n",
    ".assign(fit = lambda df: df.apply(lambda r: {k:r[k] for k in [\"train_loss\", \n",
    "                                                              \"dev_loss\", \n",
    "                                                              \"epoch\"]}, \n",
    "                                  axis = 1))\\\n",
    ".groupby(\"experiment_id\")\\\n",
    ".agg({\"fit\":(lambda x: min(x, key = lambda y: y[\"dev_loss\"])),\n",
    "      \"parameters\":max, \n",
    "      \"dropout\":max,\n",
    "      \"weight_decay\":max,\n",
    "      \"embedding_dimension\":max,\n",
    "      \"encoder_layers\":max,\n",
    "      \"training_minutes\":max})\\\n",
    ".assign(parameters = lambda df: df.parameters / 10**6, \n",
    "        train_loss = lambda df: df.fit.map(lambda x: x[\"train_loss\"]),\n",
    "        dev_loss = lambda df: df.fit.map(lambda x: x[\"dev_loss\"]),\n",
    "        epoch = lambda df: df.fit.map(lambda x: x[\"epoch\"]))\\\n",
    ".drop(columns = \"fit\")\n",
    "experiments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_folder = \"/home/jarobyte/scratch/guemes/icdar/fr/baseline/evaluation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_files = os.listdir(evaluation_folder)\n",
    "len(evaluation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36657757507b44e8b09ae3e434912633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>improvement</th>\n",
       "      <th>window</th>\n",
       "      <th>decoding</th>\n",
       "      <th>window_size</th>\n",
       "      <th>inference_seconds</th>\n",
       "      <th>cer_before</th>\n",
       "      <th>cer_after</th>\n",
       "      <th>weighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22717012_8</td>\n",
       "      <td>-76.334</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>100</td>\n",
       "      <td>2.449</td>\n",
       "      <td>5.531</td>\n",
       "      <td>9.752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22717012_8</td>\n",
       "      <td>-166.460</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>1.187</td>\n",
       "      <td>5.531</td>\n",
       "      <td>14.737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22717012_8</td>\n",
       "      <td>-25.367</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>100</td>\n",
       "      <td>3.852</td>\n",
       "      <td>5.531</td>\n",
       "      <td>6.933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22717012_8</td>\n",
       "      <td>-661.308</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>3.167</td>\n",
       "      <td>5.531</td>\n",
       "      <td>42.104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22717012_8</td>\n",
       "      <td>-13.650</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>12.205</td>\n",
       "      <td>5.531</td>\n",
       "      <td>6.285</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id  improvement    window decoding  window_size  \\\n",
       "0    22717012_8      -76.334  disjoint   greedy          100   \n",
       "1    22717012_8     -166.460  disjoint   greedy           50   \n",
       "2    22717012_8      -25.367  disjoint     beam          100   \n",
       "3    22717012_8     -661.308  disjoint     beam           50   \n",
       "4    22717012_8      -13.650   sliding   greedy           50   \n",
       "\n",
       "   inference_seconds  cer_before  cer_after weighting  \n",
       "0              2.449       5.531      9.752       NaN  \n",
       "1              1.187       5.531     14.737       NaN  \n",
       "2              3.852       5.531      6.933       NaN  \n",
       "3              3.167       5.531     42.104       NaN  \n",
       "4             12.205       5.531      6.285   uniform  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.concat([pd.read_csv(evaluation_folder + f) \n",
    "                       for f in tqdm(os.listdir(evaluation_folder))])\n",
    "print(evaluation.shape)\n",
    "evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>improvement</th>\n",
       "      <th>window</th>\n",
       "      <th>decoding</th>\n",
       "      <th>window_size</th>\n",
       "      <th>inference_seconds</th>\n",
       "      <th>cer_before</th>\n",
       "      <th>cer_after</th>\n",
       "      <th>weighting</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>dev_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22717012_12</td>\n",
       "      <td>-3.402</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>11.446</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.719</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>66.326</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22717012_12</td>\n",
       "      <td>-3.402</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>11.382</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.719</td>\n",
       "      <td>bell</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>66.326</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22717012_12</td>\n",
       "      <td>-4.288</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>11.302</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.768</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>66.326</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.357</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>147.402</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.772</td>\n",
       "      <td>bell</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.357</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>150.359</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.772</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.357</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>15.843</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.772</td>\n",
       "      <td>bell</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.357</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>15.736</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.772</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.913</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>148.577</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.802</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22694232_3</td>\n",
       "      <td>-4.913</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>16.291</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.802</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>112.512</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.318</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22694232_9</td>\n",
       "      <td>-6.436</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>50</td>\n",
       "      <td>16.388</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.887</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>102.392</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.265</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id  improvement   window decoding  window_size  \\\n",
       "5   22717012_12       -3.402  sliding   greedy           50   \n",
       "6   22717012_12       -3.402  sliding   greedy           50   \n",
       "4   22717012_12       -4.288  sliding   greedy           50   \n",
       "9    22694232_3       -4.357  sliding     beam           50   \n",
       "8    22694232_3       -4.357  sliding     beam           50   \n",
       "6    22694232_3       -4.357  sliding   greedy           50   \n",
       "5    22694232_3       -4.357  sliding   greedy           50   \n",
       "7    22694232_3       -4.913  sliding     beam           50   \n",
       "4    22694232_3       -4.913  sliding   greedy           50   \n",
       "5    22694232_9       -6.436  sliding   greedy           50   \n",
       "\n",
       "   inference_seconds  cer_before  cer_after weighting  parameters  dropout  \\\n",
       "5             11.446       5.531      5.719  triangle       1.015      0.0   \n",
       "6             11.382       5.531      5.719      bell       1.015      0.0   \n",
       "4             11.302       5.531      5.768   uniform       1.015      0.0   \n",
       "9            147.402       5.531      5.772      bell       1.478      0.5   \n",
       "8            150.359       5.531      5.772  triangle       1.478      0.5   \n",
       "6             15.843       5.531      5.772      bell       1.478      0.5   \n",
       "5             15.736       5.531      5.772  triangle       1.478      0.5   \n",
       "7            148.577       5.531      5.802   uniform       1.478      0.5   \n",
       "4             16.291       5.531      5.802   uniform       1.478      0.5   \n",
       "5             16.388       5.531      5.887  triangle       1.478      0.2   \n",
       "\n",
       "   weight_decay  embedding_dimension  encoder_layers  training_minutes  \\\n",
       "5     0.000e+00                  128               2            66.326   \n",
       "6     0.000e+00                  128               2            66.326   \n",
       "4     0.000e+00                  128               2            66.326   \n",
       "9     1.000e-04                  128               3           112.512   \n",
       "8     1.000e-04                  128               3           112.512   \n",
       "6     1.000e-04                  128               3           112.512   \n",
       "5     1.000e-04                  128               3           112.512   \n",
       "7     1.000e-04                  128               3           112.512   \n",
       "4     1.000e-04                  128               3           112.512   \n",
       "5     1.000e-04                  128               3           102.392   \n",
       "\n",
       "   train_loss  dev_loss  epoch  \n",
       "5       0.176     0.289      4  \n",
       "6       0.176     0.289      4  \n",
       "4       0.176     0.289      4  \n",
       "9       0.288     0.318     10  \n",
       "8       0.288     0.318     10  \n",
       "6       0.288     0.318     10  \n",
       "5       0.288     0.318     10  \n",
       "7       0.288     0.318     10  \n",
       "4       0.288     0.318     10  \n",
       "5       0.184     0.265     12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluation.merge(experiments, right_index = True, left_on = \"experiment_id\")\\\n",
    ".sort_values(\"improvement\", ascending = False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>improvement</th>\n",
       "      <th>window</th>\n",
       "      <th>decoding</th>\n",
       "      <th>window_size</th>\n",
       "      <th>inference_seconds</th>\n",
       "      <th>cer_before</th>\n",
       "      <th>cer_after</th>\n",
       "      <th>weighting</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>embedding_dimension</th>\n",
       "      <th>encoder_layers</th>\n",
       "      <th>training_minutes</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>dev_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22722342_1</td>\n",
       "      <td>-794.926</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>178.636</td>\n",
       "      <td>5.531</td>\n",
       "      <td>49.494</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>100.375</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22722342_1</td>\n",
       "      <td>-763.683</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>179.019</td>\n",
       "      <td>5.531</td>\n",
       "      <td>47.766</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>100.375</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22722342_1</td>\n",
       "      <td>-80.815</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>100</td>\n",
       "      <td>5.624</td>\n",
       "      <td>5.531</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>100.375</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22722342_1</td>\n",
       "      <td>-810.593</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>50</td>\n",
       "      <td>178.361</td>\n",
       "      <td>5.531</td>\n",
       "      <td>50.361</td>\n",
       "      <td>bell</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>100.375</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22722342_1</td>\n",
       "      <td>-79.699</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>100</td>\n",
       "      <td>3.703</td>\n",
       "      <td>5.531</td>\n",
       "      <td>9.938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000e-04</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>100.375</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>-1313.940</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.460</td>\n",
       "      <td>5.531</td>\n",
       "      <td>78.198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.660</td>\n",
       "      <td>3.852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>-1300.408</td>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>10</td>\n",
       "      <td>3.102</td>\n",
       "      <td>5.531</td>\n",
       "      <td>77.450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.660</td>\n",
       "      <td>3.852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>-1327.743</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>5</td>\n",
       "      <td>13.673</td>\n",
       "      <td>5.531</td>\n",
       "      <td>78.962</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.660</td>\n",
       "      <td>3.852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>-1354.354</td>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>5</td>\n",
       "      <td>2.298</td>\n",
       "      <td>5.531</td>\n",
       "      <td>80.434</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.660</td>\n",
       "      <td>3.852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>-1328.154</td>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>5</td>\n",
       "      <td>13.587</td>\n",
       "      <td>5.531</td>\n",
       "      <td>78.985</td>\n",
       "      <td>triangle</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.660</td>\n",
       "      <td>3.852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id  improvement    window decoding  window_size  \\\n",
       "8     22722342_1     -794.926   sliding     beam           50   \n",
       "7     22722342_1     -763.683   sliding     beam           50   \n",
       "2     22722342_1      -80.815  disjoint     beam          100   \n",
       "9     22722342_1     -810.593   sliding     beam           50   \n",
       "0     22722342_1      -79.699  disjoint   greedy          100   \n",
       "..           ...          ...       ...      ...          ...   \n",
       "0           test    -1313.940  disjoint   greedy           10   \n",
       "2           test    -1300.408  disjoint     beam           10   \n",
       "7           test    -1327.743   sliding     beam            5   \n",
       "5           test    -1354.354   sliding   greedy            5   \n",
       "8           test    -1328.154   sliding     beam            5   \n",
       "\n",
       "    inference_seconds  cer_before  cer_after weighting  parameters  dropout  \\\n",
       "8             178.636       5.531     49.494  triangle       1.478      0.0   \n",
       "7             179.019       5.531     47.766   uniform       1.478      0.0   \n",
       "2               5.624       5.531     10.000       NaN       1.478      0.0   \n",
       "9             178.361       5.531     50.361      bell       1.478      0.0   \n",
       "0               3.703       5.531      9.938       NaN       1.478      0.0   \n",
       "..                ...         ...        ...       ...         ...      ...   \n",
       "0               0.460       5.531     78.198       NaN       1.478      0.1   \n",
       "2               3.102       5.531     77.450       NaN       1.478      0.1   \n",
       "7              13.673       5.531     78.962   uniform       1.478      0.1   \n",
       "5               2.298       5.531     80.434  triangle       1.478      0.1   \n",
       "8              13.587       5.531     78.985  triangle       1.478      0.1   \n",
       "\n",
       "    weight_decay  embedding_dimension  encoder_layers  training_minutes  \\\n",
       "8      1.000e-04                  128               3           100.375   \n",
       "7      1.000e-04                  128               3           100.375   \n",
       "2      1.000e-04                  128               3           100.375   \n",
       "9      1.000e-04                  128               3           100.375   \n",
       "0      1.000e-04                  128               3           100.375   \n",
       "..           ...                  ...             ...               ...   \n",
       "0      1.000e-03                  128               3             0.089   \n",
       "2      1.000e-03                  128               3             0.089   \n",
       "7      1.000e-03                  128               3             0.089   \n",
       "5      1.000e-03                  128               3             0.089   \n",
       "8      1.000e-03                  128               3             0.089   \n",
       "\n",
       "    train_loss  dev_loss  epoch  \n",
       "8        0.147     0.303     10  \n",
       "7        0.147     0.303     10  \n",
       "2        0.147     0.303     10  \n",
       "9        0.147     0.303     10  \n",
       "0        0.147     0.303     10  \n",
       "..         ...       ...    ...  \n",
       "0        3.660     3.852     10  \n",
       "2        3.660     3.852     10  \n",
       "7        3.660     3.852     10  \n",
       "5        3.660     3.852     10  \n",
       "8        3.660     3.852     10  \n",
       "\n",
       "[370 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(\"train_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs.query(\"experiment_id == '22717012_12'\").train_loss.plot()\n",
    "logs.query(\"experiment_id == '22717012_12'\").dev_loss.plot(ls = \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <th colspan=\"4\" halign=\"left\">disjoint</th>\n",
       "      <th colspan=\"6\" halign=\"left\">sliding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">50</th>\n",
       "      <th colspan=\"2\" halign=\"left\">100</th>\n",
       "      <th colspan=\"6\" halign=\"left\">50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoding</th>\n",
       "      <th>beam</th>\n",
       "      <th>greedy</th>\n",
       "      <th>beam</th>\n",
       "      <th>greedy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">beam</th>\n",
       "      <th colspan=\"3\" halign=\"left\">greedy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighting</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>bell</th>\n",
       "      <th>triangle</th>\n",
       "      <th>uniform</th>\n",
       "      <th>bell</th>\n",
       "      <th>triangle</th>\n",
       "      <th>uniform</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22717012_12</th>\n",
       "      <td>-70.938</td>\n",
       "      <td>-55.953</td>\n",
       "      <td>-80.742</td>\n",
       "      <td>-77.79</td>\n",
       "      <td>-9.706</td>\n",
       "      <td>-9.865</td>\n",
       "      <td>-11.374</td>\n",
       "      <td>-3.402</td>\n",
       "      <td>-3.402</td>\n",
       "      <td>-4.288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "window        disjoint                        sliding                          \\\n",
       "window_size        50              100            50                            \n",
       "decoding          beam  greedy    beam greedy    beam                  greedy   \n",
       "weighting          NaN     NaN     NaN    NaN    bell triangle uniform   bell   \n",
       "experiment_id                                                                   \n",
       "22717012_12    -70.938 -55.953 -80.742 -77.79  -9.706   -9.865 -11.374 -3.402   \n",
       "\n",
       "window                          \n",
       "window_size                     \n",
       "decoding                        \n",
       "weighting     triangle uniform  \n",
       "experiment_id                   \n",
       "22717012_12     -3.402  -4.288  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.query(\"experiment_id == '22717012_12'\")\\\n",
    "[[\"experiment_id\", \"window\", \"window_size\", \"decoding\", \"weighting\", \"improvement\"]]\\\n",
    ".sort_values([\"window\", \"window_size\", \"decoding\", \"weighting\"])\\\n",
    ".pivot(index = \"experiment_id\", \n",
    "       values = \"improvement\", \n",
    "       columns = [\"window\", \"window_size\", \"decoding\", \"weighting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
